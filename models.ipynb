{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 17:22:49 | INFO | fairseq.tasks.speech_to_text | dictionary size (vocab.txt): 75\n"
     ]
    }
   ],
   "source": [
    "from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\n",
    "from fairseq.models.text_to_speech.hub_interface import TTSHubInterface\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "models, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n",
    "    \"facebook/fastspeech2-en-ljspeech\",\n",
    "    arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 17:31:53 | INFO | fairseq.models.text_to_speech.vocoder | loaded HiFiGAN checkpoint from C:/Users/runze/.cache/fairseq/facebook--fastspeech2-en-ljspeech.main.a3e3e5e2e62bb7ca7514b11aa469e9c5b01a20bf/hifigan.bin\n"
     ]
    }
   ],
   "source": [
    "model = models[0]\n",
    "TTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)\n",
    "generator = task.build_generator(models, cfg)\n",
    "\n",
    "text = \"The following system shown below in Figure 3 is used for imaging tissues and measuring fluorescence from it in endoscopy. The scanning fiber core diameter is ~ 5 mm while the collection fibers core diameter is 200 mm. The lens assembly creates an imaging system (M=1, NA =0.075, F_obj = 1mm) to image the scanning fiber spot into the tissue surface, located 1 mm away from the tip of the collection fibers.\"\n",
    "\n",
    "model = model.to(\"cuda:0\")\n",
    "\n",
    "sample = TTSHubInterface.get_model_input(task, text)\n",
    "sample[\"net_input\"][\"src_tokens\"] = sample[\"net_input\"][\"src_tokens\"].to(\"cuda:0\")\n",
    "sample[\"net_input\"][\"src_lengths\"] = sample[\"net_input\"][\"src_lengths\"].to(\"cuda:0\")\n",
    "wav, rate = TTSHubInterface.get_prediction(task, model, generator, sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "data = wav.cpu().numpy() # 44100 random samples between -1 and 1\n",
    "scaled = np.int16(data/np.max(np.abs(data)) * 32767)\n",
    "write('test.wav', rate, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48b17a399d4c7de465ada73120c63e00fef005f5a9afab28909b4870be1ea5c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
